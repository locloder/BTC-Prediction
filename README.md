# HOW TO RUN THIS 
step 1: have llama2 running in wsl on default (11434) port.

step 2: run parsing.py.

step 3: run crypto.py.

step 3: run ai_request.py.



